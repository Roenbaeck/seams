# Discrete-to-Continuum Metrics from Scalar Fields

This repository accompanies the paper **“Discrete-to-Continuum Metrics from Scalar Fields”**.
It contains:

- the LaTeX source ([ExRelSeam.tex](ExRelSeam.tex)),
- scripts to reproduce the numerical validation and figures,
- pre-generated figures in [figures/](figures/).

The core idea is **seam-driven geometry**: start from a scalar field $s$ (a *seam*), apply an explicit *rule* that turns $s$ into local geometric data (e.g. edge lengths), and then obtain a global metric as an induced shortest-path distance.

## Paper highlights (what to look for)

- **Arithmetic-mean conformal graph rule.** Edge lengths are generated by endpoint averaging of $e^{s}$:
	$$\ell_s(u,v)=\ell_0(u,v)\,\tfrac{1}{2}\bigl(e^{s(u)}+e^{s(v)}\bigr).$$
	This is contrasted in the paper with the classical *geometric-mean* convention used in standard discrete conformal geometry.
- **Discrete-to-continuum guarantee.** On quasi-uniform sampling sequences with sufficiently dense neighborhood-style graphs (plus an asymptotically geodesic spanner-type hypothesis), the induced graph shortest-path metric converges to the smooth conformal metric at an $O(h)$ rate (Gromov--Hausdorff and uniform error bounds).
- **Curvature sensitivity identity.** At $s=0$, the Jacobian of angle-defect curvature w.r.t. the seam matches the cotangent Laplacian.
- **Inverse metric/edge design becomes a convex quadratic program.** With the substitution $X_u=e^{s(u)}$, fitting edge weights reduces to a strictly convex quadratic problem governed by the **signless Laplacian** on non-bipartite graphs.

## Repository layout

- [ExRelSeam.tex](ExRelSeam.tex): paper source
- [validation.py](validation.py): numerical sweep + derivative checks + convergence study
- [make_figures.py](make_figures.py): regenerates the paper figures into [figures/](figures/)

## Python setup

The scripts require Python 3 with:

- `numpy`
- `scipy`
- `matplotlib`

Example (macOS/Linux):

```bash
python -m venv .venv
source .venv/bin/activate
python -m pip install --upgrade pip
python -m pip install numpy scipy matplotlib
```

## Running the numerical validation

Run:

```bash
python validation.py
```

What it does:

- runs a sweep over mesh sizes and noise levels,
- checks gradients/Hessian-vector products by finite differences,
- reports a metrics table (including $R^2$ for seam recovery),
- shows summary plots,
- optionally runs an $O(h)$ convergence study (can take longer).

Notes:

- The script uses `matplotlib.pyplot.show()` and is easiest to run in an environment with a display.
- If you want a faster run, set `RUN_CONVERGENCE_STUDY = False` near the top of [validation.py](validation.py).
- For large-$n$ cases the script automatically falls back from Delaunay to a symmetric k-NN graph for scalability.

## Regenerating the paper figures

Run:

```bash
python make_figures.py
```

This writes `PDF` and `PNG` files to [figures/](figures/):

- `fig1_seam_curvature`
- `fig2_convergence`
- `fig3_inverse_design`

The figure generation is deterministic (fixed RNG seeds) to support reproducibility.

## Building the PDF

If you have a LaTeX toolchain installed:

```bash
latexmk -pdf ExRelSeam.tex
```

### Computers \& Graphics (Elsevier CAS template)

This repo also includes an Elsevier CAS-compatible wrapper that targets *Computers \& Graphics*:

- Main file: [cag_manuscript.tex](cag_manuscript.tex)
- Included body (paper content): [ExRelSeam_body.tex](ExRelSeam_body.tex)
- CAS class/style files (kept at repo root for convenience): [cas-sc.cls](cas-sc.cls), [cas-dc.cls](cas-dc.cls), [cas-common.sty](cas-common.sty)

To compile locally (if you have LaTeX installed):

```bash
latexmk -pdf cag_manuscript.tex
```

To compile in an online service (e.g., OpenAI Prism), upload at least:

- [cag_manuscript.tex](cag_manuscript.tex)
- [ExRelSeam_body.tex](ExRelSeam_body.tex)
- [cas-sc.cls](cas-sc.cls) and [cas-common.sty](cas-common.sty)
- the full [figures/](figures/) folder

## License

MIT — see [LICENSE](LICENSE).

## Authorship note

The manuscript acknowledges that large language models were used for drafting/polishing under the author’s oversight (see the paper’s acknowledgments section).
